'''
ìŒì„± í™”ì ë¶„ì„ ë° ë¹„êµ ìœ í‹¸ë¦¬í‹° / pyannote-audioë¥¼ ì‚¬ìš©í•œ speaker verification
pip install pyannote-audio librosa soundfile pandas scipy
'''
from pyannote.audio import Audio
from pyannote.audio.pipelines.speaker_verification import PretrainedSpeakerEmbedding
from pyannote.core import Segment
from scipy.spatial.distance import cosine
import torch
import librosa
import soundfile as sf
import os
import voice_management

from kei import HF_TOKEN

HF_TOKEN = HF_TOKEN
embedding_model = None
audio = None
current_model_type = None
current_device = None

# ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ë“¤
AVAILABLE_MODELS = {
    'ecapa': "speechbrain/spkrec-ecapa-voxceleb",  # ê¸°ì¡´ ëª¨ë¸
    'xvector': "speechbrain/spkrec-xvect-voxceleb",  # X-Vector (ë” ë‚˜ì€ ì„±ëŠ¥)
    'resnet': "speechbrain/spkrec-resnet34-voxceleb",  # ResNet ê¸°ë°˜ (ë” ë‚˜ì€ ì„±ëŠ¥)
    'wavlm': "microsoft/wavlm-base-plus-sv"  # WavLM ê¸°ë°˜ (ìµœì‹ , ê°€ì¥ ì¢‹ì€ ì„±ëŠ¥)
}

# Speaker embedding ëª¨ë¸ ì´ˆê¸°í™”
def init_speaker_model(model_type='ecapa', use_gpu=False):
    global embedding_model, audio, current_model_type, current_device
    
    # ë™ì¼í•œ ì„¤ì •ì´ë©´ ì¬ì´ˆê¸°í™”í•˜ì§€ ì•ŠìŒ
    if (embedding_model is not None and 
        current_model_type == model_type and 
        current_device == ('cuda' if use_gpu else 'cpu')):
        return
    
    # ë””ë°”ì´ìŠ¤ ì„¤ì •
    device = torch.device('cuda' if use_gpu and torch.cuda.is_available() else 'cpu')
    device_name = "GPU" if device.type == 'cuda' else "CPU"
    
    # ëª¨ë¸ ì„ íƒ
    if model_type not in AVAILABLE_MODELS:
        print(f"Warning: Unknown model type '{model_type}', using 'ecapa' as fallback")
        model_type = 'ecapa'
    
    model_path = AVAILABLE_MODELS[model_type]
    model_name = model_type.upper()
    
    print(f"Loading {model_name} model on {device_name}...")
    
    try:
        if model_type == 'wavlm':
            # WavLM ëª¨ë¸ì€ ë‹¤ë¥¸ ë°©ì‹ìœ¼ë¡œ ë¡œë“œí•  ìˆ˜ ìˆìŒ
            from transformers import Wav2Vec2Model, Wav2Vec2Processor
            try:
                embedding_model = PretrainedSpeakerEmbedding(
                    model_path,
                    use_auth_token=HF_TOKEN
                )
            except:
                print(f"Failed to load WavLM model, falling back to X-Vector...")
                model_path = AVAILABLE_MODELS['xvector']
                model_name = "X-Vector"
                embedding_model = PretrainedSpeakerEmbedding(
                    model_path,
                    use_auth_token=HF_TOKEN
                )
        else:
            embedding_model = PretrainedSpeakerEmbedding(
                model_path,
                use_auth_token=HF_TOKEN
            )
        
        # GPUë¡œ ì´ë™
        if use_gpu and torch.cuda.is_available():
            embedding_model = embedding_model.to(device)
            print(f"Model moved to GPU (CUDA)")
        
        audio = Audio(sample_rate=16000)
        
        current_model_type = model_type
        current_device = device.type
        
        print(f"{model_name} model loaded successfully on {device_name}")
        
    except Exception as e:
        print(f"Error loading {model_name} model: {e}")
        if model_type != 'ecapa':
            print("Falling back to ECAPA-TDNN model...")
            return init_speaker_model('ecapa', use_gpu)
        else:
            raise e

# ìŒì„± íŒŒì¼ë¡œë¶€í„° ì„ë² ë”© ì¶”ì¶œ
def extract_embedding(file_path, model_type='ecapa', use_gpu=False):
    init_speaker_model(model_type, use_gpu)
    
    if not os.path.exists(file_path):
        raise FileNotFoundError(f"Audio file not found: {file_path}")
    
    try:
        # 1ì°¨ ì‹œë„: librosa ì‚¬ìš©
        duration = librosa.get_duration(filename=file_path)
        segment = Segment(0, duration)
        waveform, sample_rate = audio.crop(file_path, segment)
        
        # mono ì±„ë„ë¡œ ê°•ì œ ë³€í™˜ (pyannoteëŠ” 1ì±„ë„ë§Œ ì§€ì›)
        if waveform.shape[0] > 1:
            waveform = waveform.mean(dim=0, keepdim=True)
        
        # GPU ì‚¬ìš©ì‹œ í…ì„œë¥¼ GPUë¡œ ì´ë™
        device = torch.device('cuda' if use_gpu and torch.cuda.is_available() else 'cpu')
        waveform = waveform.to(device)
        
        with torch.no_grad():
            return embedding_model(waveform[None])
            
    except Exception as e:
        print(f"Error with librosa for {file_path}: {type(e).__name__} - {e}")
        print("Trying with soundfile as fallback...")
        
        try:
            # 2ì°¨ ì‹œë„: soundfile ì‚¬ìš©
            data, sample_rate = sf.read(file_path)
            
            # ìŠ¤í…Œë ˆì˜¤ë¥¼ ëª¨ë…¸ë¡œ ë³€í™˜ (í•„ìš”ì‹œ)
            if len(data.shape) > 1:
                data = data.mean(axis=1)
            
            # ìƒ˜í”Œë ˆì´íŠ¸ ë³€í™˜ (16kHzë¡œ ë§ì¶”ê¸°)
            if sample_rate != 16000:
                data = librosa.resample(data, orig_sr=sample_rate, target_sr=16000)
                sample_rate = 16000
            
            # torch tensorë¡œ ë³€í™˜
            waveform = torch.tensor(data).unsqueeze(0).float()
            
            # mono ì±„ë„ë¡œ ê°•ì œ ë³€í™˜ (pyannoteëŠ” 1ì±„ë„ë§Œ ì§€ì›)
            if waveform.shape[0] > 1:
                waveform = waveform.mean(dim=0, keepdim=True)
            
            # GPU ì‚¬ìš©ì‹œ í…ì„œë¥¼ GPUë¡œ ì´ë™
            device = torch.device('cuda' if use_gpu and torch.cuda.is_available() else 'cpu')
            waveform = waveform.to(device)
            
            with torch.no_grad():
                return embedding_model(waveform)
                
        except Exception as e2:
            print(f"Error with soundfile fallback for {file_path}:")
            print(f"  Error type: {type(e2).__name__}")
            print(f"  Error message: {e2}")
            import traceback
            print(f"  Traceback: {traceback.format_exc()}")
            return None

# ë‘ ì„ë² ë”© ê°„ì˜ cosine similarity ê³„ì‚°
def calculate_similarity(embedding1, embedding2):
    if embedding1 is None or embedding2 is None:
        return 0.0
    
    try:
        emb1 = embedding1.squeeze()
        emb2 = embedding2.squeeze()
        similarity = 1 - cosine(emb1, emb2)
        return similarity
    except Exception as e:
        print(f"Error calculating similarity: {e}")
        return 0.0

# ë‘ ìŒì„± íŒŒì¼ì˜ ìœ ì‚¬ë„ ë¹„êµ
def compare_audio_files(audio_path1, audio_path2, model_type='ecapa', use_gpu=False):
    embedding1 = extract_embedding(audio_path1, model_type, use_gpu)
    embedding2 = extract_embedding(audio_path2, model_type, use_gpu)
    
    if embedding1 is None or embedding2 is None:
        return 0.0
    
    return calculate_similarity(embedding1, embedding2)

# ì…ë ¥ ìŒì„±ì´ íŠ¹ì • ìºë¦­í„°ì˜ ìŒì„±ê³¼ ì¼ì¹˜í•˜ëŠ”ì§€ í™•ì¸
def identify_speaker(input_audio_path, character_name, emotion='normal', threshold=0.6, model_type='ecapa', use_gpu=False):
    # ìºë¦­í„°ì˜ ê¸°ì¤€ ìŒì„± ì •ë³´ ê°€ì ¸ì˜¤ê¸°
    prompt_info = voice_management.get_prompt_info_from_name(character_name, emotion)
    
    if prompt_info is None:
        return {
            'is_match': False,
            'similarity': 0.0,
            'character': character_name,
            'reference_path': None,
            'error': f'No reference audio found for character: {character_name}'
        }
    
    reference_path = prompt_info.get('wav_path')
    if not reference_path or not os.path.exists(reference_path):
        return {
            'is_match': False,
            'similarity': 0.0,
            'character': character_name,
            'reference_path': reference_path,
            'error': f'Reference audio file not found: {reference_path}'
        }
    
    # ìŒì„± ë¹„êµ
    similarity = compare_audio_files(input_audio_path, reference_path, model_type, use_gpu)
    is_match = (similarity >= threshold)
    
    return {
        'is_match': is_match,
        'similarity': similarity,
        'character': character_name,
        'reference_path': reference_path,
        'threshold': threshold,
        'model_type': model_type,
        'device': 'GPU' if use_gpu and torch.cuda.is_available() else 'CPU'
    }

# ì…ë ¥ ìŒì„±ì„ ì—¬ëŸ¬ ìºë¦­í„°ì™€ ë¹„êµí•˜ì—¬ ê°€ì¥ ìœ ì‚¬í•œ ìºë¦­í„° ì°¾ê¸°
def identify_speaker_from_multiple_characters(input_audio_path, character_list=None, threshold=0.6, model_type='ecapa', use_gpu=False):
    if character_list is None:
        # voice_managementì—ì„œ ëª¨ë“  ìºë¦­í„° ì´ë¦„ ê°€ì ¸ì˜¤ê¸°
        try:
            character_list = voice_management.get_voice_name()
        except Exception as e:
            return {
                'best_match': None,
                'best_similarity': 0.0,
                'all_results': [],
                'is_match': False,
                'error': f'Failed to get character list: {e}'
            }
    
    all_results = []
    best_match = None
    best_similarity = 0.0
    
    for character in character_list:
        result = identify_speaker(input_audio_path, character, threshold=threshold, model_type=model_type, use_gpu=use_gpu)
        all_results.append({
            'character': character,
            'similarity': result['similarity'],
            'is_match': result['is_match']
        })
        
        if result['similarity'] > best_similarity:
            best_similarity = result['similarity']
            best_match = character
    
    return {
        'best_match': best_match,
        'best_similarity': best_similarity,
        'all_results': sorted(all_results, key=lambda x: x['similarity'], reverse=True),
        'is_match': best_similarity >= threshold,
        'threshold': threshold,
        'model_type': model_type,
        'device': 'GPU' if use_gpu and torch.cuda.is_available() else 'CPU'
    }

# ì—¬ëŸ¬ ìŒì„± íŒŒì¼ë“¤ ê°„ì˜ ìœ ì‚¬ë„ í–‰ë ¬ ê³„ì‚°
def get_speaker_similarity_matrix(audio_paths, model_type='ecapa', use_gpu=False):
    print("ğŸ”„ Extracting embeddings...")
    embeddings = {}
    
    for path in audio_paths:
        if os.path.exists(path):
            embeddings[path] = extract_embedding(path, model_type, use_gpu)
        else:
            print(f"Warning: File not found - {path}")
            embeddings[path] = None
    
    print("ğŸ“Š Calculating similarities...")
    similarity_matrix = []
    
    for path1 in audio_paths:
        row = []
        for path2 in audio_paths:
            if embeddings[path1] is None or embeddings[path2] is None:
                similarity = 0.0
            else:
                similarity = calculate_similarity(embeddings[path1], embeddings[path2])
            row.append(similarity)
        similarity_matrix.append(row)
    
    return similarity_matrix

# ëª¨ë¸ ì „ì—­ ë³€ìˆ˜ ì´ˆê¸°í™”
def reset_model_globals():
    global embedding_model, current_model_type, current_device
    embedding_model = None
    current_model_type = None
    current_device = None

# ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ì •ë³´ ì¶œë ¥
def print_available_models():
    print("ğŸ¯ Available Speaker Verification Models:")
    print("   ecapa  : ECAPA-TDNN (ê¸°ë³¸ ëª¨ë¸, ì•ˆì •ì )")
    print("   xvector: X-Vector (ë” ë‚˜ì€ ì„±ëŠ¥)")  
    print("   resnet : ResNet-34 (ë” ë‚˜ì€ ì„±ëŠ¥)")
    print("   wavlm  : WavLM (ìµœì‹ , ê°€ì¥ ì¢‹ì€ ì„±ëŠ¥)")
    print()
    print("ğŸ“Š Performance comparison (ì¼ë°˜ì ):")
    print("   ECAPA-TDNN < X-Vector â‰ˆ ResNet < WavLM")
    print("   CPU ì†ë„  : ResNet > ECAPA > X-Vector > WavLM")
    print("   GPU ì†ë„  : ëª¨ë“  ëª¨ë¸ ìœ ì‚¬")
    print()

if __name__ == "__main__":
    import glob
    
    # ========== ëª¨ë¸ ë° GPU ì„¤ì • ==========
    # ì‚¬ìš©í•  ëª¨ë¸ ì„ íƒ: 'ecapa', 'xvector', 'resnet', 'wavlm'
    MODEL_TYPE = 'ecapa'  # ê¸°ë³¸ê°’: ecapa (ê¸°ì¡´ ëª¨ë¸)
    # MODEL_TYPE = 'xvector'  # X-Vector (ë” ë‚˜ì€ ì„±ëŠ¥)
    # MODEL_TYPE = 'resnet'   # ResNet ê¸°ë°˜ (ë” ë‚˜ì€ ì„±ëŠ¥)
    MODEL_TYPE = 'wavlm'    # WavLM ê¸°ë°˜ (ìµœì‹ , ê°€ì¥ ì¢‹ì€ ì„±ëŠ¥)
    
    # GPU ì‚¬ìš© ì—¬ë¶€
    USE_GPU = True  # True: GPU ì‚¬ìš©, False: CPU ì‚¬ìš©
    
    # ì‚¬ìš©í•  ì„¤ì • ì¶œë ¥
    device_name = "GPU" if USE_GPU and torch.cuda.is_available() else "CPU"
    print(f"ğŸš€ Configuration:")
    print(f"   Model: {MODEL_TYPE.upper()}")
    print(f"   Device: {device_name}")
    if USE_GPU and not torch.cuda.is_available():
        print("   Warning: GPU requested but not available, using CPU")
    print(f"   Available models: {list(AVAILABLE_MODELS.keys())}")
    print()

    # í…ŒìŠ¤íŠ¸ í´ë”ì˜ wav íŒŒì¼ë“¤ ê°€ì ¸ì˜¤ê¸°
    test_folder = "./test/voice_speech_diarization"
    wav_files = glob.glob(os.path.join(test_folder, "*.wav"))
    
    if not wav_files:
        print("No test files available.")
        exit()
    
    print(f"Found {len(wav_files)} test files:")
    for i, file_path in enumerate(wav_files, 1):
        print(f"  {i}. {os.path.basename(file_path)}")
    print()
    
    # ê° wav íŒŒì¼ì— ëŒ€í•´ í…ŒìŠ¤íŠ¸ ìˆ˜í–‰
    for test_file in wav_files:
        file_name = os.path.basename(test_file)
        print(f"{'='*50}")
        print(f"Testing: {file_name}")
        print(f"{'='*50}")
        
        # 1. íŠ¹ì • ìºë¦­í„°ë“¤ê³¼ ê°œë³„ ë¹„êµ í…ŒìŠ¤íŠ¸
        # FILE_PATH = './voices/info.json'
        test_characters = []  # í…ŒìŠ¤íŠ¸í•  ìºë¦­í„° ëª©ë¡
        test_characters.append('arona')
        test_characters.append('plana')
        test_characters.append('mika')
        test_characters.append('yuuka')
        test_characters.append('noa')
        test_characters.append('koyuki')
        test_characters.append('nagisa')
        test_characters.append('mari')
        test_characters.append('kisaki')
        test_characters.append('miyako')
        test_characters.append('ui')
        test_characters.append('seia')
        # test_characters.append('prana')

        print(f"[{file_name}] === íŠ¹ì • ìºë¦­í„°ë“¤ê³¼ ê°œë³„ ë¹„êµ í…ŒìŠ¤íŠ¸ ===")
        
        for char in test_characters:
            try:
                result = identify_speaker(test_file, char, model_type=MODEL_TYPE, use_gpu=USE_GPU)
                reference_file = os.path.basename(result.get('reference_path', '')) if result.get('reference_path') else 'N/A'
                match_indicator = "âœ“" if result['is_match'] else "âœ—"
                device_used = result.get('device', 'N/A')
                
                print(f"  {char}: {result['similarity']:.4f} {match_indicator} (ref: {reference_file}) [{device_used}]")
                
                if 'error' in result:
                    print(f"    Error: {result['error']}")
            except Exception as e:
                print(f"  {char}: Error - {e}")
        print()
        
    # ========== ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ í…ŒìŠ¤íŠ¸ ==========
    if False:
        print("=" * 60)
        print("ğŸš€ MODEL PERFORMANCE COMPARISON TEST")
        print("=" * 60)
        
        import time
        
        # í…ŒìŠ¤íŠ¸í•  ëª¨ë“  ì¡°í•©
        test_configs = [
            ('ecapa', False),   # ECAPA + CPU
            ('ecapa', True),    # ECAPA + GPU
            ('xvector', False), # X-Vector + CPU
            ('xvector', True),  # X-Vector + GPU
            ('resnet', False),  # ResNet + CPU
            ('resnet', True),   # ResNet + GPU
            ('wavlm', False),   # WavLM + CPU
            ('wavlm', True),    # WavLM + GPU
        ]
        
        # í…ŒìŠ¤íŠ¸ìš© íŒŒì¼ ì„ íƒ (ì²« ë²ˆì§¸ íŒŒì¼ ì‚¬ìš©)
        if wav_files:
            test_file = wav_files[0]
            test_char = 'arona'  # í…ŒìŠ¤íŠ¸ ìºë¦­í„°
            
            results = []
            
            print(f"Testing with file: {os.path.basename(test_file)}")
            print(f"Testing character: {test_char}")
            print()
            
            for model_type, use_gpu in test_configs:
                device_name = "GPU" if use_gpu and torch.cuda.is_available() else "CPU"
                print(f"Testing {model_type.upper()} on {device_name}...")
                try:
                    # ê¸°ì¡´ ëª¨ë¸ ì œê±°ë¥¼ ìœ„í•œ í•¨ìˆ˜ í˜¸ì¶œ
                    reset_model_globals()
                    
                    # ëª¨ë¸ ë¡œë”© ì‹œê°„ ì¸¡ì •
                    start_time = time.time()
                    
                    # ëª¨ë¸ ë¡œë”©
                    init_speaker_model(model_type, use_gpu)
                    model_load_time = time.time() - start_time
                    
                    # ë‹¨ì¼ ì¶”ë¡  ì‹œê°„ ì¸¡ì • (Warm-up)
                    start_time = time.time()
                    result = identify_speaker(test_file, test_char, model_type=model_type, use_gpu=use_gpu)
                    warmup_time = time.time() - start_time
                    
                    # ì‹¤ì œ ì¶”ë¡  ì‹œê°„ ì¸¡ì • (5íšŒ í‰ê· )
                    inference_times = []
                    for _ in range(5):
                        start_time = time.time()
                        result = identify_speaker(test_file, test_char, model_type=model_type, use_gpu=use_gpu)
                        inference_time = time.time() - start_time
                        inference_times.append(inference_time)
                    
                    avg_inference_time = sum(inference_times) / len(inference_times)
                    similarity = result['similarity']
                    
                    results.append({
                        'model': model_type.upper(),
                        'device': device_name,
                        'model_load_time': model_load_time,
                        'warmup_time': warmup_time,
                        'avg_inference_time': avg_inference_time,
                        'similarity': similarity,
                        'success': True
                    })
                    
                    print(f"  âœ“ Model Load: {model_load_time:.3f}s")
                    print(f"  âœ“ Warm-up: {warmup_time:.3f}s") 
                    print(f"  âœ“ Avg Inference: {avg_inference_time:.3f}s")
                    print(f"  âœ“ Similarity: {similarity:.4f}")
                    print()
                    
                except Exception as e:
                    print(f"  âŒ Error: {e}")
                    results.append({
                        'model': model_type.upper(),
                        'device': device_name,
                        'model_load_time': 0,
                        'warmup_time': 0,
                        'avg_inference_time': 0,
                        'similarity': 0,
                        'success': False,
                        'error': str(e)
                    })
                    print()
            
            # ê²°ê³¼ ìš”ì•½ í…Œì´ë¸”
            print("=" * 80)
            print("ğŸ“Š PERFORMANCE SUMMARY")
            print("=" * 80)
            print(f"{'Model':<10} {'Device':<6} {'Load(s)':<8} {'Warmup(s)':<10} {'Inference(s)':<12} {'Similarity':<10} {'Status':<10}")
            print("-" * 80)
            
            for result in results:
                if result['success']:
                    status = "âœ“ OK"
                    print(f"{result['model']:<10} {result['device']:<6} {result['model_load_time']:<8.3f} "
                        f"{result['warmup_time']:<10.3f} {result['avg_inference_time']:<12.3f} "
                        f"{result['similarity']:<10.4f} {status:<10}")
                else:
                    status = "âŒ FAIL"
                    print(f"{result['model']:<10} {result['device']:<6} {'N/A':<8} {'N/A':<10} {'N/A':<12} {'N/A':<10} {status:<10}")
            
            print("-" * 80)
            
            # ì„±ê³µí•œ ê²°ê³¼ë§Œìœ¼ë¡œ ìˆœìœ„ ë§¤ê¸°ê¸°
            successful_results = [r for r in results if r['success']]
            
            if successful_results:
                print("\nğŸ† RANKINGS:")
                
                # ë¡œë”© ì‹œê°„ ìˆœìœ„
                print("\nâš¡ Fastest Model Loading:")
                sorted_by_load = sorted(successful_results, key=lambda x: x['model_load_time'])
                for i, result in enumerate(sorted_by_load[:3], 1):
                    print(f"  {i}. {result['model']} ({result['device']}): {result['model_load_time']:.3f}s")
                
                # ì¶”ë¡  ì‹œê°„ ìˆœìœ„
                print("\nğŸš€ Fastest Inference:")
                sorted_by_inference = sorted(successful_results, key=lambda x: x['avg_inference_time'])
                for i, result in enumerate(sorted_by_inference[:3], 1):
                    print(f"  {i}. {result['model']} ({result['device']}): {result['avg_inference_time']:.3f}s")
                
                # ìœ ì‚¬ë„ ìˆœìœ„ (ë†’ì€ ìˆœ)
                print("\nğŸ¯ Highest Similarity:")
                sorted_by_similarity = sorted(successful_results, key=lambda x: x['similarity'], reverse=True)
                for i, result in enumerate(sorted_by_similarity[:3], 1):
                    print(f"  {i}. {result['model']} ({result['device']}): {result['similarity']:.4f}")
                
                # GPU vs CPU ë¹„êµ
                print("\nğŸ’¡ GPU vs CPU Analysis:")
                gpu_results = [r for r in successful_results if r['device'] == 'GPU']
                cpu_results = [r for r in successful_results if r['device'] == 'CPU']
                
                if gpu_results and cpu_results:
                    avg_gpu_inference = sum(r['avg_inference_time'] for r in gpu_results) / len(gpu_results)
                    avg_cpu_inference = sum(r['avg_inference_time'] for r in cpu_results) / len(cpu_results)
                    speedup = avg_cpu_inference / avg_gpu_inference if avg_gpu_inference > 0 else 0
                    
                    print(f"  Average GPU inference: {avg_gpu_inference:.3f}s")
                    print(f"  Average CPU inference: {avg_cpu_inference:.3f}s")
                    print(f"  GPU Speedup: {speedup:.2f}x")
                
            print("\n" + "=" * 60)
        
    print("\nTest completed.")
